"""
Streamlit Data Viz App - Version API avec Batch Forecast
Visualisation avanc√©e avec appel √† l'API Modal pour les pr√©visions
"""
from __future__ import annotations
import io
import numpy as np
import plotly.graph_objects as go
import logging
from pathlib import Path
import requests
import streamlit as st
import pandas as pd
import tempfile
import os
from datetime import datetime

# Configuration
IS_STREAMLIT_CLOUD = os.getenv("STREAMLIT_RUNTIME_ENV") == "cloud" or not os.path.exists("/home")

if not IS_STREAMLIT_CLOUD:
    TEMP_DIR = Path(tempfile.gettempdir()) / "dataviz_cache"
    try:
        TEMP_DIR.mkdir(parents=True, exist_ok=True)
    except Exception:
        TEMP_DIR = Path(tempfile.gettempdir())

    logger = logging.getLogger("DataVizApp")
    logger.setLevel(logging.INFO)
    try:
        LOG_PATH = TEMP_DIR / "dataviz_app.log"
        if not logger.handlers:
            fh = logging.FileHandler(LOG_PATH, encoding="utf-8")
            fmt = logging.Formatter("[%(asctime)s] [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
            fh.setFormatter(fmt)
            logger.addHandler(fh)
    except Exception:
        pass
else:
    logger = logging.getLogger("DataVizApp")
    logger.addHandler(logging.NullHandler())

# Configuration API Modal
try:
    MODAL_API_URL = st.secrets["MODAL_API_URL"]
except (KeyError, FileNotFoundError):
    MODAL_API_URL = "https://hichemsaada0--forecast-api-predict-api.modal.run"

# =========================
# Fonctions utilitaires
# =========================

def prepare_daily_df(df, col_article="Description article", col_date="Date de livraison", col_qte="Quantite"):
    """Pr√©pare un DataFrame avec 1 ligne par (article, date) et quantit√©s = 0 si absence."""
    df[col_date] = pd.to_datetime(df[col_date], dayfirst=True, errors="coerce")
    df[col_qte] = (
        df[col_qte]
        .astype(str)
        .str.replace(",", "", regex=False)
        .str.replace("\u00a0", "", regex=False)
        .astype(float)
    )

    grouped = (
        df.groupby([col_article, col_date], as_index=False)[col_qte]
        .sum()
        .rename(columns={col_qte: "Quantit√©_totale"})
    )

    all_dates = pd.date_range(start=grouped[col_date].min(), end=grouped[col_date].max(), freq="D")
    all_articles = grouped[col_article].unique()
    full_index = pd.MultiIndex.from_product([all_articles, all_dates], names=[col_article, col_date])

    result = (
        grouped
        .set_index([col_article, col_date])
        .reindex(full_index, fill_value=0)
        .reset_index()
    )

    return result


def aggregate_quantities(df_daily, freq="D"):
    """Agr√®ge les quantit√©s par article sur la fr√©quence donn√©e."""
    if freq == "D":
        out = df_daily.copy()
        out = out.rename(columns={"Date de livraison": "P√©riode"})
        return out

    agg = (
        df_daily
        .groupby(["Description article", pd.Grouper(key="Date de livraison", freq=freq)])["Quantit√©_totale"]
        .sum()
        .reset_index()
        .rename(columns={"Date de livraison": "P√©riode"})
    )
    return agg


def call_modal_api(series_data, horizon, dates=None, product_name="Unknown"):
    """Appelle l'API Modal pour obtenir des pr√©visions."""
    payload = {
        "product_name": product_name,
        "series": series_data.tolist() if isinstance(series_data, np.ndarray) else list(series_data),
        "horizon": horizon,
    }

    if dates is not None:
        payload["dates"] = [d.isoformat() if hasattr(d, 'isoformat') else str(d) for d in dates]

    try:
        response = requests.post(MODAL_API_URL, json=payload, timeout=600)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        logger.error(f"API Error for {product_name}: {e}")
        return {"success": False, "error": str(e)}


def create_forecast_excel_with_sum(forecast_df, product_name):
    """Cr√©e un fichier Excel avec ligne de somme."""
    # Ajouter ligne de somme
    sum_row = {}
    for col in forecast_df.columns:
        if col == "Date":
            sum_row[col] = "TOTAL"
        elif pd.api.types.is_numeric_dtype(forecast_df[col]):
            sum_row[col] = forecast_df[col].sum()
        else:
            sum_row[col] = ""

    df_with_sum = pd.concat([forecast_df, pd.DataFrame([sum_row])], ignore_index=True)

    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        df_with_sum.to_excel(writer, sheet_name="Pr√©visions", index=False)

        # Formater la derni√®re ligne (somme) en gras
        workbook = writer.book
        worksheet = writer.sheets["Pr√©visions"]

        from openpyxl.styles import Font
        last_row = len(df_with_sum) + 1
        for cell in worksheet[last_row]:
            cell.font = Font(bold=True)

    buffer.seek(0)
    return buffer


# =========================
# Interface Streamlit
# =========================

st.set_page_config(page_title="Data Viz - Pr√©visions IA", layout="wide")
st.title("üìä Visualisation & Pr√©visions IA par Article")

st.markdown(
    "Importez votre fichier (CSV ou Excel) contenant au minimum : "
    "`Description article`, `Date de livraison`, `Quantite`."
)

uploaded_file = st.file_uploader("Choisissez votre fichier", type=["csv", "xlsx"])

if uploaded_file is not None:
    # Lecture du fichier
    if uploaded_file.name.lower().endswith(".csv"):
        df_raw = pd.read_csv(uploaded_file, sep=";")
    else:
        df_raw = pd.read_excel(uploaded_file)

    st.success("‚úÖ Fichier charg√© avec succ√®s")

    with st.expander("üìã Aper√ßu des donn√©es brutes"):
        st.dataframe(df_raw.head(10), use_container_width=True)

    # Pr√©paration du DataFrame journalier
    df_daily = prepare_daily_df(df_raw)

    # ==========
    # Classement des produits
    # ==========
    st.subheader("üèÜ Classement des produits par quantit√© mensuelle (cumul√©e)")

    df_monthly_all = aggregate_quantities(df_daily, freq="M")
    ranking = (
        df_monthly_all
        .groupby("Description article")["Quantit√©_totale"]
        .sum()
        .sort_values(ascending=False)
        .reset_index()
        .rename(columns={"Quantit√©_totale": "Quantit√©_mensuelle_cumul√©e"})
    )

    st.dataframe(ranking, use_container_width=True)

    # ==========
    # ONGLETS : Article Unique vs Batch
    # ==========
    tab1, tab2 = st.tabs(["üì¶ Pr√©vision Article Unique", "üöÄ Pr√©vision Batch (Multiples Articles)"])

    # ========================================
    # TAB 1 : ARTICLE UNIQUE
    # ========================================
    with tab1:
        st.subheader("üîç Visualisation d√©taill√©e par article")

        articles_sorted = ranking["Description article"].tolist()

        # Recherche
        search_text = st.text_input(
            "üîé Rechercher un article :",
            value="",
            placeholder="Ex : VIVA, LINDT, PATES...",
            key="search_single"
        )

        if search_text:
            filtered_articles = [a for a in articles_sorted if search_text.lower() in a.lower()]
        else:
            filtered_articles = articles_sorted

        if not filtered_articles:
            st.warning("Aucun article ne correspond √† votre recherche.")
            st.stop()

        selected_article = st.selectbox("üì¶ Article :", filtered_articles, key="select_single")

        freq_label = st.radio("üìÖ Fr√©quence d'agr√©gation :", ("Jour", "Semaine", "Mois"), horizontal=True, key="freq_single")

        if freq_label == "Jour":
            freq = "D"
        elif freq_label == "Semaine":
            freq = "W-MON"
        else:
            freq = "M"

        df_agg = aggregate_quantities(df_daily, freq=freq)
        df_article = df_agg[df_agg["Description article"] == selected_article].copy()
        df_article = df_article.sort_values("P√©riode")

        # Trimming des dates avec z√©ros
        nonzero_mask = df_article["Quantit√©_totale"] != 0
        if nonzero_mask.any():
            first_idx = df_article.index[nonzero_mask][0]
            last_idx = df_article.index[nonzero_mask][-1]
            df_article = df_article.loc[first_idx:last_idx]

        # S√©lection de fen√™tre temporelle
        if not df_article.empty:
            min_date = df_article["P√©riode"].min().date()
            max_date = df_article["P√©riode"].max().date()

            col_start, col_end = st.columns(2)
            with col_start:
                start_date = st.date_input("üìÖ Date de d√©but", value=min_date, min_value=min_date, max_value=max_date, key="start_single")
            with col_end:
                end_date = st.date_input("üìÖ Date de fin", value=max_date, min_value=start_date, max_value=max_date, key="end_single")

            mask_window = (
                (df_article["P√©riode"] >= pd.to_datetime(start_date)) &
                (df_article["P√©riode"] <= pd.to_datetime(end_date))
            )
            df_article = df_article.loc[mask_window].copy()

            if df_article.empty:
                st.warning("La fen√™tre de dates choisie ne contient aucune donn√©e.")
                st.stop()
        else:
            st.warning("Aucune donn√©e non nulle pour cet article.")
            st.stop()

        st.write(f"üì¶ Article s√©lectionn√© : **{selected_article}**")
        st.write(f"üìä Points de donn√©es : {len(df_article)}")

        st.dataframe(df_article, use_container_width=True)

        # Graphique historique
        st.subheader("üìà Historique des quantit√©s")

        series_hist = df_article.set_index("P√©riode")["Quantit√©_totale"]

        fig_hist = go.Figure()
        fig_hist.add_trace(
            go.Scatter(
                x=series_hist.index,
                y=series_hist.values,
                mode="lines",
                name="Historique",
                line=dict(color="black", width=1.5),
            )
        )

        fig_hist.update_layout(
            template="plotly_white",
            height=400,
            margin=dict(l=40, r=20, t=40, b=40),
            xaxis_title="Date",
            yaxis_title="Quantit√©",
            legend=dict(x=0.01, y=0.99),
        )

        st.plotly_chart(fig_hist, use_container_width=True)

        # Export Excel historique avec somme
        hist_df = series_hist.to_frame(name="Quantit√©_totale").reset_index()
        hist_buffer = create_forecast_excel_with_sum(hist_df, selected_article)

        st.download_button(
            label="üì• T√©l√©charger l'historique (Excel avec TOTAL)",
            data=hist_buffer,
            file_name=f"historique_{selected_article}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="download_hist"
        )

        # Pr√©vision IA
        st.subheader("ü§ñ Pr√©vision IA (via API Modal)")

        horizon_choice = st.selectbox(
            "Horizon de pr√©vision :",
            ["Aucune", "7 jours", "30 jours", "60 jours", "90 jours"],
            index=0,
            key="horizon_single"
        )

        if horizon_choice == "Aucune":
            forecast_horizon = None
        elif horizon_choice == "7 jours":
            forecast_horizon = 7
        elif horizon_choice == "30 jours":
            forecast_horizon = 30
        elif horizon_choice == "60 jours":
            forecast_horizon = 60
        else:
            forecast_horizon = 90

        run_forecast = st.button("üöÄ Lancer la pr√©vision IA", key="run_single")

        if forecast_horizon is not None and run_forecast:
            with st.spinner("‚è≥ Appel de l'API Modal en cours..."):
                result = call_modal_api(
                    series_data=series_hist.values,
                    horizon=forecast_horizon,
                    dates=series_hist.index,
                    product_name=selected_article
                )
                # Stocker dans session_state
                st.session_state.single_forecast_result = {
                    'result': result,
                    'series_hist': series_hist,
                    'forecast_horizon': forecast_horizon,
                    'selected_article': selected_article
                }

        # Afficher depuis session_state si disponible
        if 'single_forecast_result' in st.session_state:
            stored = st.session_state.single_forecast_result
            result = stored['result']
            series_hist = stored['series_hist']
            forecast_horizon = stored['forecast_horizon']
            selected_article = stored['selected_article']

            if result and result.get("success"):
                st.success(f"‚úÖ Pr√©vision r√©ussie avec le mod√®le : **{result['model_used']}**")

                # Affichage diagnostics
                st.caption("üìä Diagnostics du routage intelligent :")
                routing_info = result.get("routing_info", {})
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Ratio de z√©ros", f"{routing_info.get('zero_ratio', 0)*100:.1f}%")
                with col2:
                    st.metric("Dispersion", f"{routing_info.get('dispersion', 0):.3f}")
                with col3:
                    st.metric("Autocorr√©lation", f"{routing_info.get('acf_lag1', 0):.3f}")

                # Construction de l'index futur
                if isinstance(series_hist.index, pd.DatetimeIndex):
                    inferred_freq = pd.infer_freq(series_hist.index)
                    if inferred_freq is None:
                        inferred_freq = "D"
                    start_future = series_hist.index[-1] + pd.tseries.frequencies.to_offset(inferred_freq)
                    future_index = pd.date_range(start=start_future, periods=forecast_horizon, freq=inferred_freq)
                else:
                    last_idx = series_hist.index[-1]
                    future_index = np.arange(last_idx + 1, last_idx + 1 + forecast_horizon)

                # Extraction des r√©sultats
                predictions = np.array(result["predictions"])
                lower_bound = np.array(result["lower_bound"])
                upper_bound = np.array(result["upper_bound"])
                simulated_path = np.array(result["simulated_path"])
                median_predictions = result.get("median_predictions")

                # Graphique historique + pr√©visions
                st.subheader("üìä Historique et pr√©visions")

                fig_pred = go.Figure()

                # Historique
                fig_pred.add_trace(
                    go.Scatter(
                        x=series_hist.index,
                        y=series_hist.values,
                        mode="lines",
                        name="Historique",
                        line=dict(color="black", width=1.5),
                    )
                )

                # Pr√©vision moyenne
                fig_pred.add_trace(
                    go.Scatter(
                        x=future_index,
                        y=predictions,
                        mode="lines",
                        name="Pr√©vision (moyenne)",
                        line=dict(color="blue", width=2),
                    )
                )

                # Intervalle de confiance
                fig_pred.add_trace(
                    go.Scatter(
                        x=future_index,
                        y=upper_bound,
                        mode="lines",
                        name="IC 95% (haut)",
                        line=dict(color="rgba(0,100,255,0.3)", width=1, dash="dot"),
                        showlegend=False,
                    )
                )

                fig_pred.add_trace(
                    go.Scatter(
                        x=future_index,
                        y=lower_bound,
                        mode="lines",
                        name="IC 95%",
                        line=dict(color="rgba(0,100,255,0.3)", width=1, dash="dot"),
                        fill="tonexty",
                        fillcolor="rgba(0,100,255,0.2)",
                    )
                )

                # M√©diane si disponible
                if median_predictions is not None:
                    fig_pred.add_trace(
                        go.Scatter(
                            x=future_index,
                            y=median_predictions,
                            mode="lines",
                            name="Pr√©vision (m√©diane)",
                            line=dict(color="green", width=2, dash="dash"),
                        )
                    )

                # Trajectoire simul√©e
                if result["model_used"] == "BayesianLSTM":
                    label = "Trajectoire simul√©e (MC Dropout)"
                    color = "rgba(124, 252, 0, 0.9)"
                elif result["model_used"] == "SparseSpikeForecaster":
                    label = "Pics p√©riodiques simul√©s"
                    color = "rgba(255, 165, 0, 0.9)"
                else:
                    label = "Sc√©nario simul√© 0/spikes"
                    color = "rgba(255, 0, 0, 0.9)"

                fig_pred.add_trace(
                    go.Scatter(
                        x=future_index,
                        y=simulated_path,
                        mode="markers+lines",
                        name=label,
                        line=dict(color=color, width=1.5),
                        marker=dict(size=6),
                    )
                )

                fig_pred.update_layout(
                    template="plotly_white",
                    height=500,
                    xaxis_title="Temps",
                    yaxis_title="Quantit√©",
                    legend=dict(x=0.01, y=0.99),
                    title=f"Pr√©visions H={forecast_horizon} - {result['model_used']}",
                )

                st.plotly_chart(fig_pred, use_container_width=True)

                # Export Excel pr√©visions avec somme
                forecast_df = pd.DataFrame({
                    "Date": future_index,
                    "Pr√©vision_moyenne": predictions,
                    "IC_95_bas": lower_bound,
                    "IC_95_haut": upper_bound,
                    "Trajectoire_simul√©e": simulated_path,
                })

                if median_predictions is not None:
                    forecast_df["Pr√©vision_m√©diane"] = median_predictions

                forecast_buffer = create_forecast_excel_with_sum(forecast_df, selected_article)

                st.download_button(
                    label="üì• T√©l√©charger les pr√©visions (Excel avec TOTAL)",
                    data=forecast_buffer,
                    file_name=f"previsions_{selected_article}_H{forecast_horizon}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_forecast_single"
                )

            elif result:
                st.error(f"‚ùå Erreur lors de la pr√©vision : {result.get('error', 'Erreur inconnue')}")

    # ========================================
    # TAB 2 : BATCH FORECAST
    # ========================================
    with tab2:
        st.subheader("üöÄ Pr√©vision Batch - Multiples Articles")
        st.markdown("Lancez des pr√©visions sur plusieurs articles en une seule fois et t√©l√©chargez tous les r√©sultats.")

        # S√©lection des articles
        batch_search = st.text_input(
            "üîé Filtrer les articles :",
            value="",
            placeholder="Tapez pour filtrer...",
            key="search_batch"
        )

        articles_sorted = ranking["Description article"].tolist()
        if batch_search:
            filtered_batch = [a for a in articles_sorted if batch_search.lower() in a.lower()]
        else:
            filtered_batch = articles_sorted

        selected_articles = st.multiselect(
            "üì¶ S√©lectionnez les articles (plusieurs possibles) :",
            filtered_batch,
            default=[],
            key="select_batch"
        )

        st.write(f"**{len(selected_articles)}** article(s) s√©lectionn√©(s)")

        # Param√®tres batch
        col1, col2 = st.columns(2)
        with col1:
            batch_freq = st.radio("üìÖ Fr√©quence :", ("Jour", "Semaine", "Mois"), horizontal=True, key="freq_batch")
        with col2:
            batch_horizon = st.selectbox(
                "üéØ Horizon de pr√©vision :",
                ["7 jours", "30 jours", "60 jours", "90 jours"],
                index=1,
                key="horizon_batch"
            )

        if batch_freq == "Jour":
            freq_batch_val = "D"
        elif batch_freq == "Semaine":
            freq_batch_val = "W-MON"
        else:
            freq_batch_val = "M"

        if batch_horizon == "7 jours":
            horizon_batch_val = 7
        elif batch_horizon == "30 jours":
            horizon_batch_val = 30
        elif batch_horizon == "60 jours":
            horizon_batch_val = 60
        else:
            horizon_batch_val = 90

        run_batch = st.button("üöÄ Lancer le Batch Forecast", key="run_batch", type="primary")

        if run_batch and len(selected_articles) > 0:
            st.info(f"üîÑ Traitement de {len(selected_articles)} article(s)...")

            # Initialiser stockage des r√©sultats
            st.session_state.batch_results = {}  # Reset
            st.session_state.all_forecasts = []  # Reset
            st.session_state.batch_config = {
                'freq': freq_batch_val,
                'horizon': horizon_batch_val
            }

            progress_bar = st.progress(0)
            status_text = st.empty()

            all_forecasts = []

            for idx, article in enumerate(selected_articles):
                status_text.text(f"‚è≥ Traitement de {article} ({idx+1}/{len(selected_articles)})...")

                # Pr√©parer donn√©es
                df_agg_batch = aggregate_quantities(df_daily, freq=freq_batch_val)
                df_art = df_agg_batch[df_agg_batch["Description article"] == article].copy()
                df_art = df_art.sort_values("P√©riode")

                # Trimming
                nonzero_mask = df_art["Quantit√©_totale"] != 0
                if nonzero_mask.any():
                    first_idx = df_art.index[nonzero_mask][0]
                    last_idx = df_art.index[nonzero_mask][-1]
                    df_art = df_art.loc[first_idx:last_idx]

                if df_art.empty:
                    st.warning(f"‚ö†Ô∏è Pas de donn√©es pour {article}, ignor√©.")
                    continue

                series_data = df_art.set_index("P√©riode")["Quantit√©_totale"]

                # Appel API
                result = call_modal_api(
                    series_data=series_data.values,
                    horizon=horizon_batch_val,
                    dates=series_data.index,
                    product_name=article
                )

                if result and result.get("success"):
                    # Stocker r√©sultat
                    st.session_state.batch_results[article] = result

                    # Construction future index
                    if isinstance(series_data.index, pd.DatetimeIndex):
                        inferred_freq = pd.infer_freq(series_data.index)
                        if inferred_freq is None:
                            inferred_freq = "D"
                        start_future = series_data.index[-1] + pd.tseries.frequencies.to_offset(inferred_freq)
                        future_index = pd.date_range(start=start_future, periods=horizon_batch_val, freq=inferred_freq)
                    else:
                        last_idx = series_data.index[-1]
                        future_index = np.arange(last_idx + 1, last_idx + 1 + horizon_batch_val)

                    # Cr√©er DataFrame pr√©vision
                    forecast_df = pd.DataFrame({
                        "Article": article,
                        "Date": future_index,
                        "Pr√©vision_moyenne": result["predictions"],
                        "IC_95_bas": result["lower_bound"],
                        "IC_95_haut": result["upper_bound"],
                        "Trajectoire_simul√©e": result["simulated_path"],
                        "Mod√®le": result["model_used"]
                    })

                    if result.get("median_predictions"):
                        forecast_df["Pr√©vision_m√©diane"] = result["median_predictions"]

                    all_forecasts.append(forecast_df)

                else:
                    st.warning(f"‚ö†Ô∏è √âchec pour {article}: {result.get('error', 'Erreur inconnue')}")

                progress_bar.progress((idx + 1) / len(selected_articles))

            # Stocker all_forecasts dans session_state
            st.session_state.all_forecasts = all_forecasts

            status_text.text("‚úÖ Batch termin√© !")
            st.success(f"‚úÖ Pr√©visions g√©n√©r√©es pour {len(all_forecasts)}/{len(selected_articles)} article(s)")

        # Afficher depuis session_state si disponible
        if 'all_forecasts' in st.session_state and len(st.session_state.all_forecasts) > 0:
            all_forecasts = st.session_state.all_forecasts
            freq_batch_val = st.session_state.batch_config['freq']
            horizon_batch_val = st.session_state.batch_config['horizon']

            if True:  # Always display if we have results
                st.subheader("üìä R√©sum√© des pr√©visions")

                summary_data = []
                for article, res in st.session_state.batch_results.items():
                    summary_data.append({
                        "Article": article,
                        "Mod√®le utilis√©": res["model_used"],
                        "Total pr√©vu (moyenne)": sum(res["predictions"]),
                        "Zero ratio": f"{res['routing_info']['zero_ratio']*100:.1f}%"
                    })

                summary_df = pd.DataFrame(summary_data)
                st.dataframe(summary_df, use_container_width=True)

                # Visualisation individuelle par article
                st.subheader("üìä Visualisation par article")

                selected_viz_article = st.selectbox(
                    "S√©lectionnez un article pour voir son graphique :",
                    list(st.session_state.batch_results.keys()),
                    key="viz_article_select"
                )

                if selected_viz_article:
                    viz_result = st.session_state.batch_results[selected_viz_article]

                    # R√©cup√©rer les donn√©es historiques de cet article
                    df_agg_viz = aggregate_quantities(df_daily, freq=freq_batch_val)
                    df_art_viz = df_agg_viz[df_agg_viz["Description article"] == selected_viz_article].copy()
                    df_art_viz = df_art_viz.sort_values("P√©riode")

                    # Trimming
                    nonzero_mask_viz = df_art_viz["Quantit√©_totale"] != 0
                    if nonzero_mask_viz.any():
                        first_idx_viz = df_art_viz.index[nonzero_mask_viz][0]
                        last_idx_viz = df_art_viz.index[nonzero_mask_viz][-1]
                        df_art_viz = df_art_viz.loc[first_idx_viz:last_idx_viz]

                    series_viz = df_art_viz.set_index("P√©riode")["Quantit√©_totale"]

                    # Construction future index
                    if isinstance(series_viz.index, pd.DatetimeIndex):
                        inferred_freq_viz = pd.infer_freq(series_viz.index)
                        if inferred_freq_viz is None:
                            inferred_freq_viz = "D"
                        start_future_viz = series_viz.index[-1] + pd.tseries.frequencies.to_offset(inferred_freq_viz)
                        future_index_viz = pd.date_range(start=start_future_viz, periods=horizon_batch_val, freq=inferred_freq_viz)
                    else:
                        last_idx_viz = series_viz.index[-1]
                        future_index_viz = np.arange(last_idx_viz + 1, last_idx_viz + 1 + horizon_batch_val)

                    # Cr√©er graphique
                    fig_viz = go.Figure()

                    # Historique
                    fig_viz.add_trace(
                        go.Scatter(
                            x=series_viz.index,
                            y=series_viz.values,
                            mode="lines",
                            name="Historique",
                            line=dict(color="black", width=1.5),
                        )
                    )

                    # Pr√©vision moyenne
                    fig_viz.add_trace(
                        go.Scatter(
                            x=future_index_viz,
                            y=viz_result["predictions"],
                            mode="lines",
                            name="Pr√©vision (moyenne)",
                            line=dict(color="blue", width=2),
                        )
                    )

                    # IC
                    fig_viz.add_trace(
                        go.Scatter(
                            x=future_index_viz,
                            y=viz_result["upper_bound"],
                            mode="lines",
                            name="IC 95%",
                            line=dict(color="rgba(0,100,255,0.3)", width=1, dash="dot"),
                            showlegend=False,
                        )
                    )

                    fig_viz.add_trace(
                        go.Scatter(
                            x=future_index_viz,
                            y=viz_result["lower_bound"],
                            mode="lines",
                            name="IC 95%",
                            line=dict(color="rgba(0,100,255,0.3)", width=1, dash="dot"),
                            fill="tonexty",
                            fillcolor="rgba(0,100,255,0.2)",
                        )
                    )

                    # Trajectoire
                    if viz_result["model_used"] == "BayesianLSTM":
                        label_viz = "Trajectoire simul√©e (MC Dropout)"
                        color_viz = "rgba(124, 252, 0, 0.9)"
                    elif viz_result["model_used"] == "SparseSpikeForecaster":
                        label_viz = "Pics p√©riodiques simul√©s"
                        color_viz = "rgba(255, 165, 0, 0.9)"
                    else:
                        label_viz = "Sc√©nario simul√© 0/spikes"
                        color_viz = "rgba(255, 0, 0, 0.9)"

                    fig_viz.add_trace(
                        go.Scatter(
                            x=future_index_viz,
                            y=viz_result["simulated_path"],
                            mode="markers+lines",
                            name=label_viz,
                            line=dict(color=color_viz, width=1.5),
                            marker=dict(size=6),
                        )
                    )

                    fig_viz.update_layout(
                        template="plotly_white",
                        height=500,
                        xaxis_title="Temps",
                        yaxis_title="Quantit√©",
                        legend=dict(x=0.01, y=0.99),
                        title=f"{selected_viz_article} - {viz_result['model_used']}",
                    )

                    st.plotly_chart(fig_viz, use_container_width=True)

                    # T√©l√©chargement individuel
                    st.caption(f"üì• T√©l√©chargement pour {selected_viz_article}")

                    forecast_df_viz = pd.DataFrame({
                        "Date": future_index_viz,
                        "Pr√©vision_moyenne": viz_result["predictions"],
                        "IC_95_bas": viz_result["lower_bound"],
                        "IC_95_haut": viz_result["upper_bound"],
                        "Trajectoire_simul√©e": viz_result["simulated_path"],
                    })

                    if viz_result.get("median_predictions"):
                        forecast_df_viz["Pr√©vision_m√©diane"] = viz_result["median_predictions"]

                    individual_buffer = create_forecast_excel_with_sum(forecast_df_viz, selected_viz_article)

                    st.download_button(
                        label=f"üì• T√©l√©charger pr√©vision de {selected_viz_article}",
                        data=individual_buffer,
                        file_name=f"prevision_{selected_viz_article}_H{horizon_batch_val}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"download_individual_{selected_viz_article}"
                    )

                # T√©l√©chargement group√©
                st.subheader("üì• T√©l√©chargement group√© de tous les articles")

                combined_df = pd.concat(all_forecasts, ignore_index=True)

                # Cr√©er Excel avec toutes les pr√©visions
                batch_buffer = io.BytesIO()
                with pd.ExcelWriter(batch_buffer, engine='openpyxl') as writer:
                    # Une feuille par article
                    for article in combined_df["Article"].unique():
                        article_df = combined_df[combined_df["Article"] == article].copy()
                        article_df = article_df.drop(columns=["Article"])

                        # Ajouter ligne somme
                        sum_row = {}
                        for col in article_df.columns:
                            if col == "Date":
                                sum_row[col] = "TOTAL"
                            elif col == "Mod√®le":
                                sum_row[col] = ""
                            elif pd.api.types.is_numeric_dtype(article_df[col]):
                                sum_row[col] = article_df[col].sum()
                            else:
                                sum_row[col] = ""

                        article_df_with_sum = pd.concat([article_df, pd.DataFrame([sum_row])], ignore_index=True)

                        # Nettoyer le nom de feuille (Excel interdit certains caract√®res)
                        sheet_name = article[:31]  # Excel limit
                        for char in ['\\', '/', '?', '*', '[', ']', ':']:
                            sheet_name = sheet_name.replace(char, '_')
                        sheet_name = sheet_name.strip("'")  # Pas d'apostrophe au d√©but/fin

                        article_df_with_sum.to_excel(writer, sheet_name=sheet_name, index=False)

                        # Formater derni√®re ligne
                        from openpyxl.styles import Font
                        worksheet = writer.sheets[sheet_name]
                        last_row = len(article_df_with_sum) + 1
                        for cell in worksheet[last_row]:
                            cell.font = Font(bold=True)

                    # Feuille de synth√®se
                    summary_df.to_excel(writer, sheet_name="Synth√®se", index=False)

                batch_buffer.seek(0)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label=f"üì• T√©l√©charger TOUTES les pr√©visions ({len(all_forecasts)} articles)",
                    data=batch_buffer,
                    file_name=f"batch_forecast_{timestamp}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="download_batch",
                    type="primary"
                )

        elif run_batch and len(selected_articles) == 0:
            st.warning("‚ö†Ô∏è Veuillez s√©lectionner au moins un article.")
